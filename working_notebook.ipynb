{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submissions.ab_submission.object_detector import imageDataLoader, follicleClassifier, ObjectDetector\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "train_files = glob.glob(\"./data/train/*.jpg\")\n",
    "test_files = glob.glob(\"./data/test/*.jpg\")\n",
    "train_label = pd.read_csv(\"./data/train/labels.csv\")\n",
    "test_label = pd.read_csv(\"./data/test/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./params/follicleClassifier2.model\n",
      "Fitting boxPixelClassifier\n",
      "Fitting follicleClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\4078182\\Miniconda3\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<submissions.ab_submission.object_detector.ObjectDetector at 0x146f87c4550>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ObjectDetector(ramp_mode=False)\n",
    "model.load(boxPixelClassifier=\"./params/boxPixelClassifier_opencv.joblib\", follicleClassifier=\"./params/follicleClassifier2.model\")\n",
    "model.fit(train_files, train_label)\n",
    "#model.save(boxPixelClassifier=\"./params/boxPixelClassifier_opencv.joblib\",follicleClassifier=\"./params/follicleClassifier2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = imageDataLoader(test_files, test_label[[\"filename\",\"xmin\",\"xmax\",\"ymin\",\"ymax\",\"label\"]])\n",
    "train_loader = imageDataLoader(train_files, train_label[[\"filename\",\"xmin\",\"xmax\",\"ymin\",\"ymax\",\"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_hat = model.predict(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "font_size = 60\n",
    "if os.name != 'nt':\n",
    "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/freefont/FreeMono.ttf\", font_size)\n",
    "else:\n",
    "    font = ImageFont.truetype(\"C:/Windows/Fonts/Arial/arialbd.ttf\", font_size)\n",
    "\n",
    "def write_rectangle(image, preds, folder=None, filename=None):\n",
    "    img = Image.fromarray(image)\n",
    "    img_draw = ImageDraw.Draw(img)\n",
    "    for pred in preds:\n",
    "        x1, y1, x2, y2 = pred[\"bbox\"]\n",
    "        label = pred[\"class\"]\n",
    "        img_draw.rounded_rectangle(((x1, y1), (x2,y2)), fill=None, outline=\"black\", width=5)\n",
    "        img_draw.text((x1, y1-70), label, font=font, fill=\"black\")\n",
    "\n",
    "    if folder is not None and filename is not None:\n",
    "        img.save(f\"./data/{folder}/{filename}\")\n",
    "    \n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "folder = \"test_predicted\"\n",
    "for x in test_loader.get_samples():\n",
    "    write_rectangle(x[0], y_hat[i], folder=folder, filename=test_loader.X_filenames[i])\n",
    "    i += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import tempfile\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempFolder_test = tempfile.TemporaryFile()\n",
    "tempFolder_train = tempfile.TemporaryFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class folliclesDataset(Dataset):\n",
    "    \"\"\"folliclesDataset\n",
    "    \n",
    "    This class provide a dataset for follicles algorithm training.\n",
    "    The aim is to perform all the data transform and augmentation at the same place.\n",
    "    This class provide an iterate, either it provide data in live, either it stores them in hard drive and provide them from memory \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__ (self, image_loader, data_augmentation, local_path, box_classifier = None, verbose=True):\n",
    "        \"\"\"Parameters\n",
    "            ----------\n",
    "            image_loader: object from the image loader class\n",
    "            data_augmentation: boolean, if True a data augmentation is performed\n",
    "            local_path: str, local path for data storage which are kept in memory as picke in the local_path folder\n",
    "            box_classifier: object from the box classifier class, if None no box are generated from the classifier\n",
    "            verbose: boolean, informations about current operations are displayed\n",
    "        \"\"\"\n",
    "\n",
    "        # Storing the image loader\n",
    "        self.image_loader = image_loader\n",
    "        self.box_classifier = box_classifier\n",
    "\n",
    "        # Storing the parameters\n",
    "        if local_path is not None and os.path.exists(local_path):\n",
    "            self.local_path = local_path\n",
    "        else:\n",
    "            raise Exception(\"The provided path doesn't exist.\")\n",
    "\n",
    "        self.data_augmentation = data_augmentation\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Recording metadata\n",
    "        ## Contains the dataset metadata\n",
    "        ## files metadata, files location\n",
    "        self.metadata = []\n",
    "\n",
    "        # Generating data\n",
    "        if self.verbose:\n",
    "            print(\"Generating data\")\n",
    "            self._generate_all_data()\n",
    "\n",
    "            self._write_metadata(\"/\".join([\n",
    "                self.local_path,\n",
    "                \"metadata.pickle\"\n",
    "                ])\n",
    "            )\n",
    "\n",
    "    def _generate_all_data(self, label_ratio_threshold=0.7):\n",
    "        \"\"\"Function that generate and write all the data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        label_ratio_threshold: threshold of percentage of box intersection for keeping it\n",
    "\n",
    "        Output\n",
    "        ------\n",
    "        No output. It writes all the data.\n",
    "        \"\"\"\n",
    "\n",
    "        for filename in self.image_loader.X_filenames:\n",
    "            output_data = self._generate_data(filename)\n",
    "\n",
    "            output_filenames = [\n",
    "                \"/\".join([\n",
    "                    self.local_path,\n",
    "                    str(x)+\".pickle\"\n",
    "                ]) for x in range(\n",
    "                    len(self.metadata), \n",
    "                    len(self.metadata)+len(output_data)\n",
    "            )]\n",
    "\n",
    "            for data, filename in zip(output_data, output_filenames):\n",
    "                if self.verbose:\n",
    "                    print(f\"Writting {filename}\")\n",
    "\n",
    "                output_dict = dict([(key,value) for key, value in x.items() if key not in [\"data\"]])\n",
    "                output_dict[\"filename\"] = filename\n",
    "\n",
    "                # Keeping the data in the internal metadata list\n",
    "                self.metadata = output_dict\n",
    "                # Writting file\n",
    "                with open(filename,\"w\") as f:\n",
    "                    pickle.dump(output_dict[\"data\"], \"w\")\n",
    "\n",
    "\n",
    "    def _generate_data(self, filename, label_ratio_threshold=0.7):\n",
    "        \"\"\"Generate the data from a sample\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename: str, name of the file from which we generate the data\n",
    "        label_ratio_threshold: threshold of percentage of box intersection for keeping it\n",
    "\n",
    "        Output\n",
    "        ------\n",
    "        List of dict, containing :\n",
    "            filename: name of the original file\n",
    "            width: width of the box\n",
    "            height: height of the box\n",
    "            ratio: ratio h/w of the box\n",
    "            bbox: xmin, ymin, xmax, ymax of the box\n",
    "            data: box content\n",
    "            label: label of the box \n",
    "        \"\"\"\n",
    "\n",
    "        # Getting original data and cropped data\n",
    "        original_data = self.image_loader.get_sample(filename)\n",
    "        original_image, original_boxes, original_labels = original_data[0], original_data[1], original_data[2]\n",
    "        original_image_shape = original_data[-1]\n",
    "        original_image_crop = self.image_loader.get_crop(original_image, original_boxes, data_augmentation=self.data_augmentation)\n",
    "\n",
    "        # Getting the box\n",
    "        detected_box = self.box_classifier(image_loader = self.image_loader, image_name = filename)\n",
    "\n",
    "        # Filter boxs and get labels\n",
    "        new_box_coordonates, new_box_data, new_box_labels = self._filter_box(original_image=original_image, \n",
    "                                                                            original_boxes=original_boxes, \n",
    "                                                                            original_labels=original_labels,\n",
    "                                                                            detected_box=detected_box,\n",
    "                                                                            label_ratio_threshold=label_ratio_threshold\n",
    "                                                            )\n",
    "        \n",
    "        # Creating the output data\n",
    "        output_dict = []\n",
    "        \n",
    "        ## From original data\n",
    "\n",
    "        output_data = [\n",
    "            zip(original_boxes, original_image_crop, original_labels),\n",
    "            zip(new_box_coordonates, new_box_data, new_box_labels)\n",
    "        ]\n",
    "        output_dict += [{\n",
    "            \"filename\":filename,\n",
    "            \"height\":original_image_shape[0],\n",
    "            \"width\":original_image_shape[1],\n",
    "            \"ratio\":original_image_shape[0]/original_image_shape[1],\n",
    "            \"bbox\":x[0],\n",
    "            \"data\":x[1],\n",
    "            \"label\":x[2]\n",
    "        } for data in output_data for x in data]\n",
    "\n",
    "        return output_dict\n",
    "        \n",
    "\n",
    "    def _filter_box(self, original_image, original_boxes, original_labels, detected_box, label_ratio_threshold=0.7):\n",
    "        \"\"\"Given a box list, return a filtered list and its labels\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        original_image: numpy array of size (h, w, 3) of the original image\n",
    "        original_boxes: list of original box locations in format xmin, xmax, ymin, ymax\n",
    "        original_labels: list integer corresponding of the labels of the original box\n",
    "        detected_box: list of detected box in formay xmin, ymin, xmax, ymax\n",
    "        label_ratio_threshold: threshold of percentage of box intersection for keeping it\n",
    "\n",
    "        Output\n",
    "        ------\n",
    "        Tuple new_box_coordonates, new_box_data, new_box_label :\n",
    "        - new_box_coordonates: list of xmin, ymin, xmax and ymax coordonates\n",
    "        - new_box_data: numpy array of size (h,w) which contains the content of the box\n",
    "        - new_box_label: int of the box class\n",
    "        \"\"\"\n",
    "\n",
    "        # We create a reference matrix, which contains the true labels\n",
    "        label_matrix = np.ones(original_image.shape[0:2])*-1\n",
    "        for original_box, original_label in zip(original_boxes, original_labels):\n",
    "            label_matrix[original_box[2]:original_box[3],original_box[0]:original_box[1]] = original_label\n",
    "\n",
    "        new_box_coordonates = []\n",
    "        new_box_data = []\n",
    "        new_box_label = []\n",
    "\n",
    "        for box in detected_box:\n",
    "            # Create a temporary matrix for working on data\n",
    "            working_matrix = label_matrix[box[1]:box[3],box[0]:box[2]]\n",
    "            if np.max(working_matrix) != -1:      \n",
    "                # Compute the proportion of pixels with a label\n",
    "                label_ratio = (working_matrix != -1).mean()\n",
    "                \n",
    "                if label_ratio > label_ratio_threshold:\n",
    "                    box_label = np.argmax(np.bincount(working_matrix[working_matrix != -1].astype(\"int8\")))-1\n",
    "                    box_data = original_image[box[1]:box[3], box[0]:box[2]]\n",
    "\n",
    "                    new_box_coordonates.append(box)\n",
    "                    new_box_data.append(box_data)\n",
    "                    new_box_label.append(box_label)\n",
    "\n",
    "        return new_box_coordonates, new_box_data, new_box_label\n",
    "\n",
    "    def _write_metadata(self, path):\n",
    "        \"\"\"Write the metadata in a pickle file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path: str, path where to write the metadata pickle file\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Writting metadata in {path}\")\n",
    "\n",
    "        with open(path, \"w\") as f:\n",
    "            pickle.dump(self.metadata, f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "str.join() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8772/2060134275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m test_dataset = folliclesDataset(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata_augmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlocal_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtempFolder_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbox_classifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_box_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8772/284540984.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, image_loader, data_augmentation, local_path, box_classifier, verbose)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Generating data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_all_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             self._write_metadata(\"/\".join([\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8772/284540984.py\u001b[0m in \u001b[0;36m_generate_all_data\u001b[1;34m(self, label_ratio_threshold)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0moutput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             output_filenames = [\n\u001b[0m\u001b[0;32m     64\u001b[0m                 \"/\".join(\n\u001b[0;32m     65\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8772/284540984.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             output_filenames = [\n\u001b[1;32m---> 64\u001b[1;33m                 \"/\".join(\n\u001b[0m\u001b[0;32m     65\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                     \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".pickle\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: str.join() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "test_dataset = folliclesDataset(\n",
    "    test_loader,\n",
    "    data_augmentation=False,\n",
    "    local_path=tempFolder_test.name,\n",
    "    box_classifier=model._get_box_list,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\4078182\\appdata\\local\\temp\\ipykernel_8772\\132009943.py\u001b[0m(66)\u001b[0;36m<listcomp>\u001b[1;34m()\u001b[0m\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28b293e0c0671e44c7281dde6399c7c7419d3faca031d22494da8635907ada72"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
