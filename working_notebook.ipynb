{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import check_array\n",
    "from scipy.ndimage import rotate, morphology\n",
    "from types import FunctionType\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vgg16\n",
    "import random\n",
    "import imageio\n",
    "import cv2\n",
    "from joblib import dump, load\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imageDataLoader():\n",
    "    \"\"\"imageDataLoader\n",
    "\n",
    "    Class for dataset loading.\n",
    "    This class provide numpy array given the image path and the image labels.\n",
    "    It will be used to feed the different classifiers of the current project.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__ (self, X, y=None):\n",
    "        \"\"\"imageDataLoader\n",
    "        \n",
    "        Initialisation of the image dataloader.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : np.array([str]) or [str], image paths\n",
    "        y : np.array of size (n, 6), containing : filenames, xmin, xmax, ymin, ymax and labels. Can be None. \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        self.X = check_array(X, ensure_2d=False, dtype=str)\n",
    "        self.X_filenames = [os.path.basename(x) for x in X]\n",
    "        \n",
    "        if y is not None:\n",
    "            # Checking the format of the input\n",
    "            if y.shape[1] <= 5:\n",
    "                raise ValueError(\"The input y should be of size 6.\")\n",
    "\n",
    "            self.has_y = True\n",
    "            y = check_array(y, dtype=None)\n",
    "            \n",
    "            # Storing the y_box\n",
    "            self.y_box = check_array(y[:,1:-1], dtype=int)\n",
    "\n",
    "            # Storing the y_label\n",
    "            self.y_label = check_array(y[:,-1], ensure_2d=False)\n",
    "            \n",
    "            # Storing the filenames\n",
    "            self.y_filenames = check_array(y[:,0], ensure_2d=False, dtype=str)\n",
    "\n",
    "            # Creating a list of mask for X-y correspondance\n",
    "            self.xy_mask = [x == self.y_filenames for x in self.X_filenames]\n",
    "\n",
    "        else:\n",
    "            self.has_y = False \n",
    "\n",
    "    def _load_image(self, image_path):\n",
    "        \"\"\"load_image\n",
    "\n",
    "            Function that load the image given its path\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            image_path: str, path of the image\n",
    "\n",
    "            Output\n",
    "            ------\n",
    "            Numpy array of size (w,h,3) with w the width of the image, h the height of the image\n",
    "        \"\"\"\n",
    "\n",
    "        image_data = imageio.imread(image_path)\n",
    "\n",
    "        return image_data\n",
    "\n",
    "    def __generate_augmented_images(self, image_matrix, rotations=[0,90,180,270], flip=[-1,0]):\n",
    "        \"\"\"Generation of augmentated image dataset\n",
    "\n",
    "        For a given image this function generate an augmented dataset of it.\n",
    "        The generation is performed by doing rotation and flipping\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_matrix: Numpy object of dimension (w,h), w and h being the widt and the height of the image\n",
    "        rotations: [int], angle in which the rotation should be performed, should contains 0 for keeping the original rotation\n",
    "        flip: [int], axis in which to flip, should contains -1 for keeping the original flipping\n",
    "        \"\"\"\n",
    "\n",
    "        augmented_image_matrix = []\n",
    "        for x in rotations:\n",
    "            for y in flip:\n",
    "                if y in [0,1]:\n",
    "                    flipped_image = np.flip(image_matrix, axis=y)\n",
    "                if y == -1:\n",
    "                    flipped_image = image_matrix\n",
    "                \n",
    "                flipped_rotated_image = rotate(flipped_image, angle=x, order=0)\n",
    "                augmented_image_matrix.append(flipped_rotated_image)\n",
    "\n",
    "        return augmented_image_matrix\n",
    "\n",
    "    def get_crop(self, image_array, box_array, data_augmentation=False):\n",
    "        \"\"\"Get crop data given an image and box array\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_array: numpy array of dimension (h,w)\n",
    "        box_array: list of coordonates, xmin xmax ymin ymax for each box\n",
    "        data_augmentation: boolean, default False, if true the function return an augmented dataset.\n",
    "\n",
    "        Output\n",
    "        ------\n",
    "        list of cropped images\n",
    "        \"\"\"\n",
    "\n",
    "        cropped_images = []\n",
    "\n",
    "        # Cropping the image\n",
    "        for box in box_array:\n",
    "            cropped_image = image_array[box[2]:box[3],box[0]:box[1]]\n",
    "\n",
    "            # Dataset augmentation\n",
    "            if data_augmentation == True:\n",
    "                augmented_images = self.__generate_augmented_images(cropped_image)\n",
    "                cropped_images += augmented_images\n",
    "\n",
    "                # Generating augmented labels\n",
    "                image_labels = np.repeat(image_labels, len(augmented_images))\n",
    "            else:\n",
    "                cropped_images.append(cropped_image)\n",
    "\n",
    "        return cropped_images\n",
    "\n",
    "    def get_sample(self, image_name, crop=False, pre_processing_fullimage_func=None, data_augmentation=False):\n",
    "        \"\"\"get_samples\n",
    "\n",
    "            Get the data of an image\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            image_name: str, name of the image to get\n",
    "            crop: boolean, default False, if true the function return samples of image cropped for each box\n",
    "            data_augmentation: boolean, default False, if true the function return an augmented dataset. For computational reason, this operation is only performed when crop is set to true.\n",
    "            pre_processing_fullimage_func: python function, which is applied to the full image. Set it to None if no function is applied.\n",
    "\n",
    "            Output\n",
    "            ------\n",
    "            (image_data, image_box, image_labels, original_image)\n",
    "            Tuple of numpy array containing :\n",
    "            - image_data:\n",
    "                Numpy array of size (w,h,3) with w the width of the image, h the height of the image if crop is false\n",
    "                List of n numpy array of size (w, h, 3) with n the number of box if crop is true\n",
    "            - image_box: Numpy array of size (n, 4) with n the number of box in the image and 4 representing : xmin, xmax, ymin and ymax. None if there is no label.\n",
    "            - image_labels: Numpy array of size (n, ) with n the number of box in the image. None if there is no label.\n",
    "            - image_shape : shape of the original image numpy array\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(image_name, str) is False or image_name not in self.X_filenames:\n",
    "            raise ValueError(\"The image name is invalid, check the format (should be a string) of the name and the existence of the file.\")\n",
    "\n",
    "        # Parameters checks\n",
    "        if crop is True and self.has_y is False:\n",
    "            raise Exception(\"The box sampling is not permitted if the labels are not available.\")\n",
    "        if pre_processing_fullimage_func is not None and isinstance(pre_processing_fullimage_func, FunctionType) is False:\n",
    "            raise ValueError(\"pre_processing_func is expected to be a function\")\n",
    "\n",
    "        # Loading the image\n",
    "        i = self.X_filenames.index(image_name)\n",
    "        image_path = self.X[i]\n",
    "        image_data = self._load_image(image_path)\n",
    "\n",
    "        # Loading labels and box\n",
    "        if self.has_y:\n",
    "            image_box = self.y_box[self.xy_mask[i]]\n",
    "            image_labels = self.y_label[self.xy_mask[i]]\n",
    "        else:\n",
    "            image_box, image_labels = (None, None)\n",
    "\n",
    "        # Applying pre_processing function to full image\n",
    "        if pre_processing_fullimage_func is not None:\n",
    "            image_data_preprocessed = pre_processing_fullimage_func(image_data)\n",
    "        else:\n",
    "            image_data_preprocessed = image_data\n",
    "\n",
    "        # Cropping data\n",
    "        if crop == True:\n",
    "            # Cropping the image\n",
    "            output_image = self.get_crop(image_data_preprocessed, image_box)\n",
    "        else:\n",
    "            output_image = image_data\n",
    "\n",
    "        image_shape = image_data.shape\n",
    "\n",
    "        return output_image, image_box, image_labels, image_shape\n",
    "\n",
    "    def get_samples(self, crop=False, pre_processing_fullimage_func=None, data_augmentation=False):\n",
    "        \"\"\"get_samples\n",
    "\n",
    "            Get an iterator of the data.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            crop: boolean, default False, if true the function return samples of images cropped for each box\n",
    "            data_augmentation: boolean, default False, if true the function return an augmented dataset. For computational reason, this operation is only performed when crop is set to true.\n",
    "            pre_processing_fullimage_func: python function, which is applied to the full image. Set it to None if no function is applied.\n",
    "\n",
    "            Output\n",
    "            ------\n",
    "            (image_data, image_box, image_labels, original_image)\n",
    "            Tuple of numpy array containing :\n",
    "            - image_data:\n",
    "                Numpy array of size (w,h,3) with w the width of the image, h the height of the image if crop is false\n",
    "                List of n numpy array of size (w, h, 3) with n the number of box if crop is true\n",
    "            - image_box: Numpy array of size (n, 4) with n the number of box in the image and 4 representing : xmin, xmax, ymin and ymax. None if there is no label.\n",
    "            - image_labels: Numpy array of size (n, ) with n the number of box in the image. None if there is no label.\n",
    "            - image_shape : shape of the original image numpy array\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(len(self.X_filenames)):\n",
    "            # Loading the data\n",
    "            image_name = self.X_filenames[i]\n",
    "            output_image, image_box, image_labels, image_shape = self.get_sample(image_name, crop=crop, pre_processing_fullimage_func=pre_processing_fullimage_func, data_augmentation=data_augmentation)\n",
    "\n",
    "            yield output_image, image_box, image_labels, image_shape\n",
    "\n",
    "    def _normalize_image(self, image):\n",
    "        \"\"\"_normalize_image\n",
    "\n",
    "        This function normalize the image value between 0 and 1 for each layer.\n",
    "        The idea behind this is to normalize the image according to itself, we want to make sure that it's pixel intensity is not \"shift\" and is always between 0 and 1.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image: numpy array of size (w, h, 3) containing the image. With w and h the image width and height.\n",
    "\n",
    "        Output:\n",
    "        -------\n",
    "        Numpy array of size (w, h, 3) containing the normalized image.\n",
    "        \"\"\"\n",
    "\n",
    "        # The idea behind this is to normalize the image according to itself, we want to make sure that it's pixel intensity is not \"shift\" and is always between 0 and 1.\n",
    "        image_normalized = (image-image.mean(axis=(0,1)))/(image.max(axis=(0,1))-image.min(axis=(0,1)))\n",
    "        image_normalized = (image_normalized-image_normalized.min(axis=(0,1)))\n",
    "\n",
    "        return image_normalized\n",
    "\n",
    "    def get_pixel_labels_sample(self, image_name, pre_processing_fullimage_func=None, normalize=True, random_pick=None, random_state=None, all = False):\n",
    "        \"\"\"get_pixel_samples\n",
    "    \n",
    "        For an image, it returns a pixel label dataset.\n",
    "        Each pixel which is in a box is associated with its label.\n",
    "        If the current dataset do not contains box, all the pixels of the image are returned\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_name: str, name of the image to get\n",
    "        pre_processing_fullimage_func: python function, which is applied to the full image before generating de pixel - label sample. Set it to None if no function is applied.\n",
    "        normalize: boolean, if true the pixel intensity are normalized between 0 and 1 for each color layer, the normalization is performed before appliance of the pre-processing function\n",
    "        random_pick: float, is not None, is precise the percentage of pixels to randomly select for each image\n",
    "        random_state: seed for random picking, not used if None\n",
    "        all: boolean, if True, all the pixels of the image are returned even if it contains box\n",
    "\n",
    "        Output\n",
    "        ------\n",
    "        (X, y, original_image) : tuple \n",
    "            X : numpy array of size (w*h, 3) with w and h the image width and height and y of size (w*h, 1)\n",
    "            y : if there is not label, the y is None.\n",
    "            image_shape : original image shape\n",
    "        \"\"\"\n",
    "\n",
    "        # Input checks\n",
    "        if isinstance(image_name, str) is False or image_name not in self.X_filenames:\n",
    "            raise ValueError(\"The image name is invalid, check the format (should be a string) of the name and the existence of the file.\")\n",
    "        if random_state is not None and isinstance(random_state, int) is False:\n",
    "            raise ValueError(\"random_state should be an integer or None\")\n",
    "        if random_pick is not None and (isinstance(random_pick, float) is False or not (0 < random_pick <= 1)):\n",
    "            raise ValueError(\"random_state should be an float between 0 and 1 or None\")\n",
    "\n",
    "        if random_state is not None:\n",
    "            random.seed(random_state)\n",
    "\n",
    "        # Getting the data\n",
    "        if self.has_y and all == False:\n",
    "            crop = True\n",
    "        else:\n",
    "            crop = False\n",
    "\n",
    "        image_data = self.get_sample(image_name, crop=crop, pre_processing_fullimage_func=pre_processing_fullimage_func, data_augmentation=False)\n",
    "        \n",
    "        # We need to perform it in a loop because the images are of different size\n",
    "        images_data = []\n",
    "        labels_data = []\n",
    "\n",
    "        if crop:\n",
    "            images_dataset = zip(image_data[0], image_data[2])\n",
    "        else:\n",
    "            images_dataset = [(image_data[0], None)]\n",
    "\n",
    "        for (image_data_box, image_label_box) in images_dataset:\n",
    "            \n",
    "            # Normalization of the image\n",
    "            image_data_normalized = self._normalize_image(image_data_box)\n",
    "\n",
    "            # Then we flatten the array according to each color channel\n",
    "            image_data_normalized_shape = image_data_normalized.shape\n",
    "            image_data_normalized_flatten = image_data_normalized.reshape(image_data_normalized_shape[0]*image_data_normalized_shape[1], 3)\n",
    "\n",
    "            # Randomly picking\n",
    "            if random_pick is not None:\n",
    "                random_idx = random.sample(\n",
    "                    list(range(0, image_data_normalized_flatten.shape[0])),\n",
    "                    k=int(random_pick*image_data_normalized_flatten.shape[0])\n",
    "                )\n",
    "                image_data_normalized_flatten = image_data_normalized_flatten[random_idx, :]\n",
    "\n",
    "            # Getting the y array\n",
    "            image_label_box_repeated = np.repeat(image_label_box, image_data_normalized_flatten.shape[0])\n",
    "\n",
    "            # Storing data\n",
    "            images_data.append(image_data_normalized_flatten)\n",
    "            labels_data.append(image_label_box_repeated)\n",
    "\n",
    "        X, y = (np.concatenate(x) for x in (images_data, labels_data))\n",
    "\n",
    "        return X, y, image_data[-1]\n",
    "\n",
    "    def get_pixel_labels_samples (self, pre_processing_fullimage_func=None, normalize=True, random_pick=None, random_state=None):\n",
    "        \"\"\"get_pixel_samples\n",
    "        \n",
    "            For each image, it returns a pixel label dataset.\n",
    "            Each pixel which is in a box is associated with its label.\n",
    "            If the current dataset do not contains box, all the pixels of the image are returned\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            pre_processing_fullimage_func: python function, which is applied to the full image before generating de pixel - label sample. Set it to None if no function is applied.\n",
    "            normalize: boolean, if true the pixel intensity are normalized between 0 and 1 for each color layer, the normalization is performed before appliance of the pre-processing function\n",
    "            random_pick: float, is not None, is precise the percentage of pixels to randomly select for each image\n",
    "            random_state: seed for random picking, not used if None\n",
    "\n",
    "            Output\n",
    "            ------\n",
    "            (X, y, original_image) : tuple \n",
    "                X : numpy array of size (w*h, 3) with w and h the image width and height and y of size (w*h, 1)\n",
    "                y : if there is not label, the y is None.\n",
    "                original_image : original image before cropping and pre-processing\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(len(self.X_filenames)):\n",
    "            image_name = self.X_filenames[i]\n",
    "            X, y, original_data = self.get_pixel_labels_sample(image_name, pre_processing_fullimage_func=pre_processing_fullimage_func, normalize=normalize, random_pick=random_pick, random_state=random_state)\n",
    "\n",
    "            yield X, y, original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class follicleClassifier(nn.Module):\n",
    "\n",
    "    def __init__ (self, device=\"cpu\"):\n",
    "\n",
    "        super(follicleClassifier, self).__init__()\n",
    "\n",
    "        # Device detection for NN\n",
    "        self.device = device\n",
    "\n",
    "        # Creation of the neural network\n",
    "\n",
    "        ## Creating pre-processing layer\n",
    "        preprocessing_layer = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "\n",
    "        ## Loading Inception3 and freezing the parameters\n",
    "        vgg_model = vgg16(pretrained=True)\n",
    "        for param in vgg_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        #vgg_features = vgg_model.features[0:12]\n",
    "        vgg_features = vgg_model.features\n",
    "        \n",
    "        ## Full network\n",
    "        self.network = nn.Sequential(*[\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            preprocessing_layer,\n",
    "            vgg_features,\n",
    "            nn.Conv2d(512, 512, padding=\"same\", kernel_size=(3,3), stride=(1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features=512,\n",
    "                out_features=125,\n",
    "                bias=True\n",
    "            ),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(num_features=125),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(\n",
    "                in_features=125,\n",
    "                out_features=25,\n",
    "                bias=True\n",
    "            ),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(num_features=25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(\n",
    "                in_features=25,\n",
    "                out_features=5,\n",
    "                bias=True\n",
    "            ),\n",
    "            nn.Softmax(dim=1)\n",
    "        ])\n",
    "\n",
    "        # Setting optimizer and loss\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "        # Storing in device\n",
    "        self.to(device)\n",
    "\n",
    "        # Loss history\n",
    "        self.losses = []\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"forward\n",
    "        Required to perform the forward pass of the network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : torch tensor of size (n, 3, w, h) with n the number of samples, w the image width and h the image height\n",
    "\n",
    "        Output\n",
    "        ------\n",
    "        Torch tensor of sice (n, 5) with n the number of samples and 5 the number of features\n",
    "        \"\"\"\n",
    "\n",
    "        y_hat = self.network(X)\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def fit(self, X, y, verbose=True):\n",
    "        \"\"\"fit\n",
    "        Train the neural network\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : torch tensor of size (n, 3, w, h) with n the number of samples, w the image width and h the image height,\n",
    "        y : torch tensor of size (n, 5) with n the number of samples and the number of features\n",
    "        \"\"\"\n",
    "\n",
    "        # Training mode\n",
    "        self.train()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        y_hat = self.forward(X)\n",
    "        loss = self.loss(y, y_hat)\n",
    "\n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descient step\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Keeping track of loss\n",
    "        self.losses.append(loss.item())\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"fit\n",
    "        Get the neural network prediction\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : torch tensor of size (n, 3, w, h) with n the number of samples, w the image width and h the image height,\n",
    "        \"\"\"\n",
    "\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_hat = self.forward(X)\n",
    "            \n",
    "        return y_hat\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"Save a serialized version of the model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path: str, output path for the model\n",
    "        \"\"\"\n",
    "\n",
    "        if \"box_ratio_\" in dir(self):\n",
    "            box_ratio = self.box_ratio_\n",
    "        else:\n",
    "            box_ratio = None\n",
    "\n",
    "        if \"box_size_\" in dir(self):\n",
    "            box_size = self.box_size_\n",
    "        else:\n",
    "            box_size = None\n",
    "\n",
    "        state = {\n",
    "            'state_dict': self.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'box_ratio': box_ratio,\n",
    "            'box_size': box_size\n",
    "        }\n",
    "\n",
    "        torch.save(state, path)\n",
    "\n",
    "        print(f\"Model save in {path}\")\n",
    "\n",
    "    def load_model(self, path):\n",
    "        \"\"\"Load a serialized version of the model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path: str, output path for the model\n",
    "        device: str, device in which to load the model\n",
    "        \"\"\"\n",
    "\n",
    "        state = torch.load(path, map_location = self.device)\n",
    "        self.load_state_dict(state['state_dict'])\n",
    "        self.optimizer.load_state_dict(state['optimizer'])\n",
    "\n",
    "        if state[\"box_ratio\"] is not None:\n",
    "            self.box_ratio_ = state[\"box_ratio\"]\n",
    "\n",
    "        if state[\"box_size\"] is not None:\n",
    "            self.box_size_ = state[\"box_size\"]\n",
    "\n",
    "        print(f\"Model loaded from {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class ObjectDetector:\n",
    "    def __init__(self, \n",
    "                preprocessing_boxPixelClassifier_convolve=30, \n",
    "                post_processing_boxPixelClassifier_convolve=10, \n",
    "                box_border = 1, \n",
    "                follicle_classifier_size=128,\n",
    "                n_epochs=50,\n",
    "                batch_size=30\n",
    "                ):\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        preprocessing_boxPixelClassifier_convolve: int, kernel size of the convolution performed before getting the pixel for classification\n",
    "        post_processing_boxPixelClassifier_convolve: int, kernel size of the convolution performed after classification, used to estimate the density of prediction and thus weight the pixel use for random box generation\n",
    "        box_border : float, proportion of the width and height for xmin, xmax, ymin and ymax determination of the border of the box\n",
    "        follicle_classifier_size: int, heigh of the images sent to follicleClassifier\n",
    "        n_epochs: int, number of epochs for follicle_classifier training\n",
    "        batch_size: int, batch size for prediction, prevent cuda out of memory\n",
    "        \"\"\"\n",
    "        # Class dictionnary\n",
    "        self._class_dict = {\n",
    "            0:\"Negative\",\n",
    "            1:\"Primordial\",\n",
    "            2:\"Primary\",\n",
    "            3:\"Secondary\",\n",
    "            4:\"Tertiary\"\n",
    "        }\n",
    "\n",
    "        # Device detection\n",
    "        if torch.cuda.is_available():\n",
    "            self.device=\"cuda:0\"\n",
    "        else:\n",
    "            self.device=\"cpu\"\n",
    "\n",
    "        # Loading classifier\n",
    "        self.boxPixelClassifier = DecisionTreeClassifier(max_depth=3, class_weight=\"balanced\")\n",
    "        self.follicleClassifier = follicleClassifier(device=self.device)\n",
    "\n",
    "        # Parameters initialization\n",
    "        self.preprocessing_boxPixelClassifier_convolve = preprocessing_boxPixelClassifier_convolve\n",
    "        self.post_processing_boxPixelClassifier_convolve = post_processing_boxPixelClassifier_convolve\n",
    "        self.box_border = box_border\n",
    "\n",
    "        self.erosion_dilatation_kernel = np.ones((5,5))\n",
    "        self.density_filter=np.ones((self.post_processing_boxPixelClassifier_convolve,self.post_processing_boxPixelClassifier_convolve))\n",
    "\n",
    "        self.follicle_classifier_size = follicle_classifier_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.follicleClassifier_fitted_ = False\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Defining some pre-processing functions\n",
    "        self.image_preprocessing = lambda x: cv2.filter2D(\n",
    "            x, -1, np.ones(\n",
    "                (preprocessing_boxPixelClassifier_convolve,preprocessing_boxPixelClassifier_convolve,1)\n",
    "            )/(preprocessing_boxPixelClassifier_convolve**2)\n",
    "        )\n",
    "\n",
    "        pass\n",
    "\n",
    "    def save(self, boxPixelClassifier, follicleClassifier):\n",
    "        \"\"\"save_params\n",
    "\n",
    "        Save the trained parameters of the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        boxPixelClassifier: str, the path where to save the parameters of the boxPixel, if None, no export if performed\n",
    "        follicleClassifier: str, the path where to save the parameters of the follicleClassifier, if None, no export if performed\n",
    "        \"\"\"\n",
    "        \n",
    "        if boxPixelClassifier is not None:\n",
    "            dump(self.boxPixelClassifier, boxPixelClassifier)\n",
    "\n",
    "        if follicleClassifier is not None:\n",
    "            self.follicleClassifier.save_model(follicleClassifier)\n",
    "\n",
    "    def load(self, boxPixelClassifier, follicleClassifier):\n",
    "        \"\"\"save_params\n",
    "\n",
    "        Save the trained parameters of the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        boxPixelClassifier: str, the path where to load the parameters of the boxPixel, if None, no loading if performed for boxPixelClassifier\n",
    "        follicleClassifier: str, the path where to load the parameters of the follicleClassifier, if None, no loading if performed for follicleClassifier\n",
    "        \"\"\"\n",
    "\n",
    "        if boxPixelClassifier is not None:\n",
    "            self.boxPixelClassifier = load(boxPixelClassifier)\n",
    "    \n",
    "        if follicleClassifier is not None:\n",
    "            self.follicleClassifier.load_model(follicleClassifier)\n",
    "\n",
    "    def _get_box_list(self, image_loader, image_name):\n",
    "        \"\"\"Return the box list according to an image and to the box classifier\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_loader: image loader object\n",
    "        image_name: str, filename of the image\n",
    "\n",
    "        Output\n",
    "        ------\n",
    "        List of box in the format xmin, ymin, xmax, ymax\n",
    "        \"\"\"\n",
    "\n",
    "        # Data for detection of pixel of interest\n",
    "        pixel_data = image_loader.get_pixel_labels_sample(\n",
    "            image_name,\n",
    "            pre_processing_fullimage_func=self.image_preprocessing,\n",
    "            all=True\n",
    "        )\n",
    "        X_pixel = pixel_data[0].mean(axis=1).reshape(-1,1)\n",
    "\n",
    "        # Getting prediction in 2D format\n",
    "        y_hat_pixel = self.boxPixelClassifier.predict(X_pixel)\n",
    "        y_hat_pixel = y_hat_pixel.reshape(pixel_data[-1][0:2])\n",
    "\n",
    "        # Post-processing\n",
    "\n",
    "        ## Only keep the most dense area of pixels\n",
    "        y_hat_pixel_morphology = y_hat_pixel.astype(np.uint8)\n",
    "        erosion_threshold = y_hat_pixel_morphology.mean()/10\n",
    "        y_hat_pixel_morphology_mean = y_hat_pixel_morphology.mean()\n",
    "        while y_hat_pixel_morphology_mean > erosion_threshold and y_hat_pixel_morphology_mean > 0.01:\n",
    "            y_hat_pixel_morphology = cv2.erode(y_hat_pixel_morphology, kernel=self.erosion_dilatation_kernel)\n",
    "            y_hat_pixel_morphology_mean = y_hat_pixel_morphology.mean()\n",
    "\n",
    "        ## Filtering pixel by density\n",
    "        \n",
    "        density_matrix = cv2.filter2D(y_hat_pixel_morphology, -1, self.density_filter)\n",
    "        density_matrix = density_matrix/density_matrix.max()\n",
    "        density_matrix[density_matrix < np.quantile(density_matrix[density_matrix != 0], 0.9)] = 0 # We cut the noise\n",
    "\n",
    "        y_hat_pixel_density = density_matrix*y_hat_pixel_morphology\n",
    "        y_hat_pixel_density = (y_hat_pixel_density == 1).astype(np.uint8)\n",
    "\n",
    "        ## Erode again then dilate\n",
    "        y_hat_pixel_density_erode = cv2.erode(y_hat_pixel_density, self.erosion_dilatation_kernel, iterations=3)\n",
    "        y_hat_pixel_density_erode_dilate = cv2.dilate(y_hat_pixel_density_erode, self.erosion_dilatation_kernel, iterations=2)            \n",
    "\n",
    "        # Getting box location\n",
    "        y_hat_box = []\n",
    "        box_ratio = self.follicleClassifier.box_ratio_\n",
    "        box_size = self.follicleClassifier.box_size_\n",
    "        contours, _ = cv2.findContours(y_hat_pixel_density_erode_dilate,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for c in contours:\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            x_min, y_min, x_max, y_max = x-w*self.box_border, y-h*self.box_border, x+w*(1+self.box_border), y+h*(1+self.box_border)\n",
    "\n",
    "            # Fixing the border conditions\n",
    "            y_min, x_min = tuple([x if x > 0 else 0 for x in [y_min, x_min]])\n",
    "            y_max, x_max = tuple([x if x < y else y for x, y in zip([y_max, x_max], list(y_hat_pixel_density_erode_dilate.shape))])\n",
    "            \n",
    "            nh, nw = y_max-y_min, x_max-x_min\n",
    "            if (nh)/(nw) <= box_ratio and nh*nw >= box_size :\n",
    "                x_min, y_min, x_max, y_max = int(x_min), int(y_min), int(x_max), int(y_max)\n",
    "                y_hat_box.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "        return y_hat_box\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"fit function\n",
    "\n",
    "        The main idea here is :\n",
    "         - To train a classifier to detect pixel of interest for box generation\n",
    "         - To Train a classifier to classify images from a box\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: list of file path\n",
    "        y: pandas object containing the labels\n",
    "        \"\"\"\n",
    "\n",
    "        # Loading data with the imageLoader\n",
    "        image_loader = imageDataLoader(X, y[[\"filename\",\"xmin\",\"xmax\",\"ymin\",\"ymax\",\"label\"]])\n",
    "\n",
    "        # 1. Training the boxPixelClassifier\n",
    "        print(\"Fitting boxPixelClassifier\")\n",
    "\n",
    "        # Skipping if already fitted\n",
    "\n",
    "        if \"tree_\" not in dir(self.boxPixelClassifier):\n",
    "            ## Getting the train dataset :\n",
    "            train_dataset = list(\n",
    "                image_loader.get_pixel_labels_samples(\n",
    "                    random_pick=0.01, \n",
    "                    random_state=42, \n",
    "                    pre_processing_fullimage_func=self.image_preprocessing)\n",
    "            )\n",
    "            X, y = (np.concatenate([j[i] for j in train_dataset]) for i in [0,1])\n",
    "            X = X.mean(axis=1).reshape(-1,1)\n",
    "            y = (y != 0).astype(\"int\")\n",
    "\n",
    "            self.boxPixelClassifier.fit(X,y)\n",
    "\n",
    "        # 2. Training image classifier\n",
    "        print(\"Fitting follicleClassifier\")\n",
    "\n",
    "        # Skipping if already fitted\n",
    "        if \"box_ratio_\" not in dir(self.follicleClassifier):\n",
    "\n",
    "            # Constitution of the dataset : original cropped image, and box detected by the algorithm\n",
    "            original_boxes = image_loader.y_box\n",
    "\n",
    "            # Also learning the correct h/w box ratio\n",
    "            box_ratio = np.quantile([(y[3]-y[2])/(y[1]-y[0]) for y in original_boxes], 0.95)*1.5\n",
    "            box_size = np.quantile([(y[3]-y[2])*(y[1]-y[0]) for y in original_boxes], 0.01)/2\n",
    "\n",
    "            # Storing the correct box ratio in the classifier\n",
    "            self.follicleClassifier.box_ratio_ = box_ratio\n",
    "            self.follicleClassifier.box_size_ = box_size\n",
    "\n",
    "            dataset_for_follicle_classifier = []\n",
    "            for filename in image_loader.X_filenames:\n",
    "\n",
    "                # Original image\n",
    "                original_data = image_loader.get_sample(filename)\n",
    "                original_image_crop = image_loader.get_crop(original_data[0], original_data[1])\n",
    "\n",
    "                ## Dataset from original data\n",
    "                dataset_for_follicle_classifier_original = [original_image_crop, original_data[2]]\n",
    "\n",
    "                ##  Dataset from boxes\n",
    "                ### Here we compute a matrix of zeros with the location of original labelled data, we only keep box which intersect with theses\n",
    "                boxes = self._get_box_list(image_loader=image_loader, image_name=filename)\n",
    "\n",
    "                label_matrix = np.zeros(original_data[-1][0:2])\n",
    "                for original_box, original_label in zip(original_data[1], original_data[2]):\n",
    "                    label_matrix[original_box[2]:original_box[3],original_box[0]:original_box[1]] = original_label+1\n",
    "\n",
    "                dataset_for_follicle_classifier_box_data = []\n",
    "                dataset_for_follicle_classifier_box_label = []\n",
    "                for box in boxes:\n",
    "                    tmp_matrix = label_matrix[box[1]:box[3],box[0]:box[2]]\n",
    "                    if np.max(tmp_matrix) != 0:        \n",
    "                        area = tmp_matrix.shape[0]*tmp_matrix.shape[1]\n",
    "                        n_pixels = (tmp_matrix != 0).sum()\n",
    "                        \n",
    "                        if area/n_pixels > 0.5:\n",
    "                            box_label = np.argmax(np.bincount(tmp_matrix[tmp_matrix != 0].astype(\"int8\")))-1\n",
    "                            box_data = original_data[0][box[1]:box[3], box[0]:box[2]]\n",
    "\n",
    "                            dataset_for_follicle_classifier_box_data.append(box_data)\n",
    "                            dataset_for_follicle_classifier_box_label.append(box_label)\n",
    "\n",
    "                if len(dataset_for_follicle_classifier) != 0:\n",
    "                    dataset_for_follicle_classifier.append(\n",
    "                        dataset_for_follicle_classifier_original\n",
    "                    )\n",
    "\n",
    "                if len(dataset_for_follicle_classifier_box_data) != 0:\n",
    "                    dataset_for_follicle_classifier.append(\n",
    "                        [dataset_for_follicle_classifier_box_data, dataset_for_follicle_classifier_box_label]\n",
    "                    )\n",
    "\n",
    "            tensors_for_follicle_classifier = []\n",
    "\n",
    "            for data in dataset_for_follicle_classifier:\n",
    "                x = [cv2.resize(\n",
    "                        image, \n",
    "                        (self.follicle_classifier_size,\n",
    "                        int(image.shape[0]*self.follicle_classifier_size/image.shape[1]))\n",
    "                    ) for image in data[0] if len(image.shape) == 3]\n",
    "\n",
    "                # Padding to get a dataset of same size everywhere\n",
    "                if len(x) > 0:\n",
    "                    x = nn.utils.rnn.pad_sequence([torch.tensor(data, dtype=torch.float32) for data in x], batch_first=True)\n",
    "                    x = torch.moveaxis(x, 3, 1)\n",
    "                    x = x/255 # VGG requires a normalized pixel intensity\n",
    "\n",
    "                    # One hot encoding of the labels\n",
    "                    y = nn.functional.one_hot(\n",
    "                        torch.tensor(data[1], dtype=torch.int64), \n",
    "                        num_classes=5\n",
    "                    ).float()\n",
    "\n",
    "                    tensors_for_follicle_classifier.append((x,y))\n",
    "\n",
    "            for i in range(self.n_epochs):\n",
    "                for x,y in tensors_for_follicle_classifier:\n",
    "                    x = x.to(self.device)\n",
    "                    y = y.to(self.device)\n",
    "                    \n",
    "                    self.follicleClassifier.fit(x,y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"predict function\n",
    "\n",
    "        The main idea here is :\n",
    "         - Get the pixel of interest\n",
    "         - Draw box around this pixel\n",
    "         - Provide a classification of theses box\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: list of file path\n",
    "        \"\"\"\n",
    "\n",
    "        # Loading data with the imageLoader\n",
    "        image_loader = imageDataLoader(X)\n",
    "\n",
    "        # Generating prediction\n",
    "        predictions = []\n",
    "\n",
    "        for image_name in image_loader.X_filenames:\n",
    "\n",
    "            # Getting box location\n",
    "            y_hat_box = self._get_box_list(image_loader, image_name)\n",
    "\n",
    "            # Classification of the box\n",
    "            # Get the full image\n",
    "\n",
    "            full_image = image_loader.get_sample(image_name)[0]\n",
    "            y_hat_box_image = [] # Array containing the images\n",
    "            for box in y_hat_box:\n",
    "                box_image = full_image[box[1]:box[3], box[0]:box[2]]\n",
    "                y_hat_box_image.append(box_image)\n",
    "            \n",
    "            x = [cv2.resize(\n",
    "                image, \n",
    "                (self.follicle_classifier_size,\n",
    "                int(image.shape[0]*self.follicle_classifier_size/image.shape[1]))\n",
    "            ) for image in y_hat_box_image]\n",
    "\n",
    "            # Padding to get a dataset of same size everywhere\n",
    "            x = nn.utils.rnn.pad_sequence([torch.tensor(data, dtype=torch.float32) for data in x], batch_first=True)\n",
    "            x = torch.moveaxis(x, 3, 1)\n",
    "            x = x/255 # VGG requires a normalized pixel intensity\n",
    "\n",
    "            # Getting labels\n",
    "\n",
    "            ## Getting prediction in batch\n",
    "            n_batch = x.shape[0]//self.batch_size + int(x.shape[0]%self.batch_size)\n",
    "            y_hat_proba_temp_array = []\n",
    "            for batch in range(n_batch):\n",
    "                x_temp = x[batch*self.batch_size:(batch+1)*self.batch_size].to(self.device)\n",
    "                y_hat_proba_temp = self.follicleClassifier.predict(x_temp).cpu()\n",
    "                y_hat_proba_temp_array.append(y_hat_proba_temp)\n",
    "            y_hat_proba = torch.concat(y_hat_proba_temp_array, dim=0)\n",
    "\n",
    "            y_hat_proba, y_hat_labels_id = torch.max(y_hat_proba, dim=1)\n",
    "            y_hat_labels = np.vectorize(lambda x: self._class_dict[x])(y_hat_labels_id)\n",
    "\n",
    "            predictions.append({\n",
    "                \"bbox\": y_hat_box,\n",
    "                \"images\": x,\n",
    "                \"proba\": y_hat_proba.numpy(),\n",
    "                \"proba_label_id\": y_hat_labels_id.numpy(),\n",
    "                \"class\":y_hat_labels\n",
    "            })\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "train_files = glob.glob(\"./data/train/*.jpg\")\n",
    "test_files = glob.glob(\"./data/test/*.jpg\")\n",
    "train_label = pd.read_csv(\"./data/train/labels.csv\")\n",
    "test_label = pd.read_csv(\"./data/test/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The snakeviz extension is already loaded. To reload it, use:\n",
      "  %reload_ext snakeviz\n"
     ]
    }
   ],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting boxPixelClassifier\n",
      "Fitting follicleClassifier\n"
     ]
    }
   ],
   "source": [
    "model = ObjectDetector()\n",
    "model.load(boxPixelClassifier=\"./params/boxPixelClassifier_opencv.joblib\", follicleClassifier=None)\n",
    "model.fit(train_files, train_label)\n",
    "#model.save(boxPixelClassifier=\"./params/boxPixelClassifier_opencv.joblib\",follicleClassifier=\"./params/follicleClassifier2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = imageDataLoader(test_files, test_label[[\"filename\",\"xmin\",\"xmax\",\"ymin\",\"ymax\",\"label\"]])\n",
    "train_loader = imageDataLoader(train_files, train_label[[\"filename\",\"xmin\",\"xmax\",\"ymin\",\"ymax\",\"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "font = ImageFont.truetype(\"/usr/share/fonts/truetype/freefont/FreeMono.ttf\", 60, encoding=\"unic\")\n",
    "\n",
    "def write_rectangle(image, bbox, labels, folder=None, filename=None):\n",
    "    img = Image.fromarray(image)\n",
    "    img_draw = ImageDraw.Draw(img)\n",
    "    for box,label in zip(bbox, labels):\n",
    "        x1, y1, x2, y2 = box\n",
    "        img_draw.rounded_rectangle(((x1, y1), (x2,y2)), fill=None, outline=\"black\", width=5)\n",
    "        img_draw.text((x1, y1-70), label, font=font, fill=\"black\")\n",
    "\n",
    "    if folder is not None and filename is not None:\n",
    "        img.save(f\"./data/{folder}/{filename}\")\n",
    "    \n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "folder = \"test_predicted\"\n",
    "for x in test_loader.get_samples():\n",
    "    write_rectangle(x[0], y_hat[i][\"bbox\"], y_hat[i][\"class\"], folder=folder, filename=test_loader.X_filenames[i])\n",
    "    i += 1    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28b293e0c0671e44c7281dde6399c7c7419d3faca031d22494da8635907ada72"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
